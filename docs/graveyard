Consumers Overview
==================

The Consumers library

* Introduce `ConsumeMessage(Shard, Store, message.Envelope) error`.
* Discuss Shards. 
* State stores.
* Recovery logs, Live-tailing of those stores / high availabiility.
* Consumer transactions. Low latency / high throughput.
* Queryability & Routing.


The consumers framework simplifies the development of user applications which
"consume" messages streamed from journals. Applications are empowered to keep
substantial amounts of application-defined state in an embedded database
(typically a RocksDB), and the framework manages concerns such as database
replication and recovery, distributed routing, failure recovery, and high-
availability. Applications may be very long lived and scale horizontally.


It's designed to jointly solve two key considerations that builders of event stream-based systems inevitably must answer:

 * How do my services discover new events, and how do they in turn make other services aware of events they produce (ie, publish/subscribe)?

 * How do I durably store, reference, and re-process all of my events, even those produced a very long time ago?

Traditionally  

Gazette offers a "Journal" reousrce which elegantly 

Gazette is infrastructure for building streaming platforms, consisting of a
*broker service* for durable logging and publish/subscribe, and a *consumer
framework* for long-lived, scaled, stateful, and highly-available streaming
applications written in Go.

Gazette has been continuously operated in production since early 2015,
and powers a number of critical systems and use-cases at LiveRamp.

Cluster QuickStart
~~~~~~~~~~~~~~~~~~

.. code-block:: console

    # Perform a containerized build and run project tests (requires Docker).
    # This uses the same Continuous Integration image as official builds.
    $ make as-ci target=go-test-fast

    # (If required) bootstrap a Kubernetes cluster with Helm (https://helm.sh).
    $ ./test/bootstrap_local_kubernetes.sh my-k8s-context

    # Deploy Gazette brokers to the cluster.
    $ ./test/deploy_brokers.sh my-k8s-context my-namespace
    Using context "my-k8s-context" & namespace "my-namespace"
    ... trimmed output ...
    NOTES:
    The Gazette broker cluster is now running.
    1. Get the application URL by running these commands:
      export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=gazette,app.kubernetes.io/instance=virtuous-owl" -o jsonpath="{.items[0].metadata.name}")
      echo "Visit http://127.0.0.1:8080 to use your application"
      kubectl port-forward $POD_NAME 8080:80

    # Deploy example applications to the cluster.
    $ ./test/deploy_examples.sh my-k8s-context my-namespace

    # If using MicroK8s, additional Makefile targets are provided for boostrapping
    # the cluster.
    $ make microk8s-reset
    $ make microk8s-deploy-brokers

    # Run examples in "soak test" mode. In this configuration the `stream-sum`
    # example runs indefinitely, verifying correctness of the system.
    $ make microk8s-deploy-soak

- `mk/build.mk <mk/build.mk>`_ defines the build recipes used to build and test Gazette.

- `test/ <test/>`_ has details on deployment, example applications,
  and means of provisioning a local Kubernetes cluster (eg, MicroK8s or Minikube) with a
  complete Gazette environment, including interactive examples.

Broker Service
==============

Brokers serve "Journals", a byte-oriented resource resembling a file. Journals
may be read from an arbitrary offset, they may be appended to (only), and they
may grow to an unbounded length far exceeding disk capacity.

Append operations are atomic: a writer is assured that either its entire write
is contiguously sequenced into the journal, or that none of it is. No reader
of a journal will observe a write until it has been fully committed.

The brokers provide global sequencing of client writes to journals, and replicate
those writes to ensure durability. They also serve streamed journal reads, which may
begin at any offset and will optionally block upon reaching an offset which has not
yet been written to the journal (the "write head"). In this way, read operations over
journals resemble ``tail -c ${my_offset} -f`` operations over Linux files.

Once written, Journal content is immutable, and brokers offload long-term storage of spans of journal content ("Fragments") to a backing *fragment store* provided by a BLOB storage service such as Amazon S3 or Google Cloud Storage.

Append operations are atomic: a writer is assured that either its entire write
is contiguously sequenced into the journal, or that none of it is. No reader
of a journal will observe a write until it has been fully committed.



Interacting with Brokers
~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: console

    # Port-forward to a running Gazette Pod (or, use a service IP).
    $ kubectl port-forward $A_GAZETTE_POD_NAME 8080

    # Write data to a journal using the HTTP gateway API:
    $ curl -X PUT --data-binary @- http://localhost:8080/examples/foobar << EOF
    > Hello, Gazette!
    > EOF

    $ curl http://localhost:8080/examples/foobar
    Hello, Gazette!

    # Read beginning at an arbitrary offset:
    $ curl "http://localhost:8080/examples/foobar?offset=7"
    Gazette!

    # Perform ongoing, background writes to the journal:
    $ while true; do curl -X PUT --data-binary @- http://localhost:8080/examples/foobar << EOF
    > ping
    > EOF
    > sleep 1
    > done

    # Read from an offset, continuing to stream new writes as they arrive:
    $ curl -N "http://localhost:8080/examples/foobar?offset=7&block=true"
    Gazette!
    ping
    ping
    ping
    ... etc

    # Use the gazctl CLI tool to interact with Gazette:
    $ gazctl journals list --primary
    +----------------------------------------------------+--------------------------------------+
    |                        NAME                        |               PRIMARY                |
    +----------------------------------------------------+--------------------------------------+
    | examples/foobar                                    | virtuous-owl-gazette-bc5d97fbd-8xw8s |
    | examples/stream-sum/chunks/part-000                | virtuous-owl-gazette-bc5d97fbd-8xw8s |
    | examples/stream-sum/chunks/part-001                | virtuous-owl-gazette-bc5d97fbd-8xw8s |
    | examples/stream-sum/chunks/part-002                | virtuous-owl-gazette-bc5d97fbd-8xw8s |
    |                   ... etc ...                      |                                      |
    +----------------------------------------------------+--------------------------------------+

Consumers Framework
===================

The consumers framework simplifies the development of user applications which
"consume" messages streamed from journals. Applications are empowered to keep
substantial amounts of application-defined state in an embedded database
(typically a RocksDB), and the framework manages concerns such as database
replication and recovery, distributed routing, failure recovery, and high-
availability. Applications may be very long lived and scale horizontally.
